select(subjects,number_correct)
library(plotly)
library(ggplot2)
library(reshape)
library(RColorBrewer)
library(data.table)
library(plyr)
library(dplyr)
library(MASS)
select <- dplyr::select
library(kableExtra)
library(knitr)
library(shiny)
library(DT)
options(knitr.table.format="html")
#Create color scheme
pastel_colors = brewer.pal(8, "Pastel1")
set_colors = brewer.pal(8, "Set1")
least_correct = 3
threshhold_acc = 0.60
avg_rts <- df.responses %>%
group_by(subjects) %>%
summarise(mean_rt = mean(rt_attachment,na.rm=TRUE))
outlier <- boxplot.stats(avg_rts$mean_rt)$out
p <- ggplot(avg_rts, aes(x=factor(0),y=mean_rt,subject=subjects)) +
geom_boxplot() +
geom_jitter(size = 2) +
ggtitle("Average reaction times per subject across all items")
p <- ggplotly(p,tooltip ='subjects')
p
test_correct   <- df.subjectinfo %>%
select(subjects,starts_with("correct")) %>%
mutate(number_correct = rowSums(!is.na(.[,2:ncol(.)]))) %>%
select(subjects,number_correct)
avg_unambiguous <-df.responses %>%
filter(items %in% subset_unambiguous) %>%
group_by(subjects) %>%
summarise(acc_unambiguous = mean(hits,na.rm=TRUE))
summ <- join_all(list(avg_rts,test_correct,avg_unambiguous),by='subjects')
DT::datatable(summ) %>% formatRound(columns=colnames(summ),digits=2)
outlier_indx <- avg_rts$subjects[which(round(avg_rts$mean_rt,digits=2) %in% round(outlier,digits=2))]
outlier_indx <- c(outlier_indx,summ$subjects[which(summ$number_correct < least_correct | summ$acc_unambiguous < threshhold_acc)])
outlier_indx <- unique(outlier_indx)
#Remove Outlier
df.responses <- df.responses %>%
filter(!(subjects %in% outlier_indx))
#Binomial distribution of probabilities if chance-performane is 50%
x <- seq(0,20,by = 1)
y <- dbinom(x,20,0.5)
#plot(x,y,main="Probability distribution assuming per item probability of 50%",
#      xlab="Number of correct answers per items (out of 20 answers)", ylab = "Probability")
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17)])
#first reject items based on accuracy threshold with their paired items
pairs_reject <- df.stim_acc[df.stim_acc$ID %in% items_reject$ID,]
df.responses_clean <- df.responses %>%
filter(!(items %in% pairs_reject$fullID))
#Then check if all verbs still occur twice (also for type 1 items) and reject remaining pair.
pairs_remain <- df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$items,]
pairs_remain <-  unique(pairs_remain[duplicated(pairs_remain$verb_number),"verb_number"])
items_reject2 <- df.stim_acc[!(df.stim_acc$verb_number %in% pairs_remain),]
pairs_reject2 <- df.stim_acc[df.stim_acc$ID %in% items_reject2$ID,]
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% pairs_reject2$fullID))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17)])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==1,])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==2,])
library(plotly)
library(ggplot2)
library(reshape)
library(RColorBrewer)
library(data.table)
library(plyr)
library(dplyr)
library(MASS)
select <- dplyr::select
library(kableExtra)
library(knitr)
library(shiny)
library(DT)
options(knitr.table.format="html")
#Create color scheme
pastel_colors = brewer.pal(8, "Pastel1")
set_colors = brewer.pal(8, "Set1")
stimuli         <- read.csv(file="allstimuli_new.csv",head=TRUE,sep=";",na.strings = c("","NAN"), stringsAsFactors = FALSE,encoding="UTF-8")
stimuli$fullID  <- as.character(interaction(stimuli[,c(13,3)],sep = ""))
stimuli$Condition <- as.factor(stimuli$Condition)
colnames(stimuli) <- c("Type","Pair","ID","Det.","N0","Verb","Det.2","N1","Prep.","Det.3","Adj.","N2","Attachment","Unambiguous","verb_number","fullID")
#load response file
file_names = list.files(pattern="^results",path = "allresponses",full.names = TRUE)
temp <- lapply(file_names,read.csv,sep=",",na.strings = c("","NAN"), stringsAsFactors = TRUE)
df.responses <- Reduce(function(x,y) merge(x,y,all=TRUE,sort=TRUE),temp)
#transpose and fix column names and classes
df.responses                <- setDT(df.responses,keep.rownames = TRUE)
colnames(df.responses)[1]   <- "subjects"
df.responses                <- Filter(function(x) !(all(x=="")), df.responses) #delete blank columns
setwd("/Users/sophiearana/Documents/prepositionalphrase/preps/Limesurvey/results/")
library(plotly)
library(ggplot2)
library(reshape)
library(RColorBrewer)
library(data.table)
library(plyr)
library(dplyr)
library(MASS)
select <- dplyr::select
library(kableExtra)
library(knitr)
library(shiny)
library(DT)
options(knitr.table.format="html")
#Create color scheme
pastel_colors = brewer.pal(8, "Pastel1")
set_colors = brewer.pal(8, "Set1")
stimuli         <- read.csv(file="allstimuli_new.csv",head=TRUE,sep=";",na.strings = c("","NAN"), stringsAsFactors = FALSE,encoding="UTF-8")
stimuli$fullID  <- as.character(interaction(stimuli[,c(13,3)],sep = ""))
stimuli$Condition <- as.factor(stimuli$Condition)
colnames(stimuli) <- c("Type","Pair","ID","Det.","N0","Verb","Det.2","N1","Prep.","Det.3","Adj.","N2","Attachment","Unambiguous","verb_number","fullID")
#load response file
file_names = list.files(pattern="^results",path = "allresponses",full.names = TRUE)
temp <- lapply(file_names,read.csv,sep=",",na.strings = c("","NAN"), stringsAsFactors = TRUE)
df.responses <- Reduce(function(x,y) merge(x,y,all=TRUE,sort=TRUE),temp)
#transpose and fix column names and classes
df.responses                <- setDT(df.responses,keep.rownames = TRUE)
colnames(df.responses)[1]   <- "subjects"
df.responses                <- Filter(function(x) !(all(x=="")), df.responses) #delete blank columns
#Split all item specific data from subject specific data
ind_items   <- grep("[VN]A[0-9]",colnames(df.responses),value = TRUE)
df.subjectinfo <- df.responses
df.subjectinfo[,ind_items] <- NULL
df.responses  <- df.responses[,c("subjects",ind_items),with=FALSE]
#reshape items so that each row contains info for items per subject (items repeat over rows)
ind             <- grep("^[VN]A[0-9]*$",colnames(df.responses),value = TRUE)
df.respAttach   <- df.responses[,c("subjects",ind),with=FALSE]
df.respAttach   <- melt(df.respAttach,id="subjects",value.name="response_attachment",variable.name='items')
ind             <- grep("^[VN]A[0-9]*Time$",colnames(df.responses),value = TRUE)
df.respTime     <- df.responses[,c("subjects",ind),with=FALSE]
df.respTime     <- melt(df.respTime,id="subjects",value.name="rt_attachment",variable.name='items')
ind             <- grep("\\.$",colnames(df.responses),value = TRUE)
df.respPAttach  <- df.responses[,c("subjects",ind),with=FALSE]
df.respPAttach  <- melt(df.respPAttach,id="subjects",value.name="rating_plausibility",variable.name='items')
ind             <- grep("P[VN]A[0-9]*Time$",colnames(df.responses),value = TRUE)
df.respPTime    <- df.responses[,c("subjects",ind),with=FALSE]
df.respPTime    <- melt(df.respPTime,id="subjects",value.name="rt_plausibility",variable.name='items')
df.responses    <- cbind(df.respAttach,df.respTime[,3],df.respPAttach[,3],df.respPTime[,3])
df.responses$hits <- as.numeric((grepl("N",df.responses$items) & df.responses$response_attachment == "Nomen") |
(grepl("V",df.responses$items) & df.responses$response_attachment == "Verb"))
df.responses    <- df.responses %>%
mutate(attachment = ifelse(grepl("N",items),"Noun","Verb"))
summary(df.subjectinfo$age)
summary((df.subjectinfo$interviewtime)/60)
#average accuracy of unambiguous items
subset_unambiguous <- stimuli$fullID[(stimuli$Unambiguous==1)]
sentences_unambiguous <- stimuli[(stimuli$Unambiguous==1),4:12]
sentences_unambiguous
least_correct = 3
threshhold_acc = 0.60
avg_rts <- df.responses %>%
group_by(subjects) %>%
summarise(mean_rt = mean(rt_attachment,na.rm=TRUE))
outlier <- boxplot.stats(avg_rts$mean_rt)$out
p <- ggplot(avg_rts, aes(x=factor(0),y=mean_rt,subject=subjects)) +
geom_boxplot() +
geom_jitter(size = 2) +
ggtitle("Average reaction times per subject across all items")
p <- ggplotly(p,tooltip ='subjects')
p
test_correct   <- df.subjectinfo %>%
select(subjects,starts_with("correct")) %>%
mutate(number_correct = rowSums(!is.na(.[,2:ncol(.)]))) %>%
select(subjects,number_correct)
avg_unambiguous <-df.responses %>%
filter(items %in% subset_unambiguous) %>%
group_by(subjects) %>%
summarise(acc_unambiguous = mean(hits,na.rm=TRUE))
outlier_indx <- avg_rts$subjects[which(round(avg_rts$mean_rt,digits=2) %in% round(outlier,digits=2))]
outlier_indx <- c(outlier_indx,summ$subjects[which(summ$number_correct < least_correct | summ$acc_unambiguous < threshhold_acc)])
outlier_indx <- unique(outlier_indx)
#Remove Outlier
df.responses <- df.responses %>%
filter(!(subjects %in% outlier_indx))
#Binomial distribution of probabilities if chance-performane is 50%
x <- seq(0,20,by = 1)
y <- dbinom(x,20,0.5)
#plot(x,y,main="Probability distribution assuming per item probability of 50%",
#      xlab="Number of correct answers per items (out of 20 answers)", ylab = "Probability")
df.responses$items == "NA11"
which(df.responses$items == "NA11")
length(which(df.responses$items == "NA11"))
df.responses[df.responses$items == "NA11",]
na.omit(df.responses[df.responses$items == "NA11",])
dim(na.omit(df.responses[df.responses$items == "NA11",]))
dim(na.omit(df.responses[df.responses$items == "NA1100",]))
dim(na.omit(df.responses[df.responses$items == "NA1101",]))
dim(na.omit(df.responses[df.responses$items == "NA1102",]))
dim(na.omit(df.responses[df.responses$items == "NA1200",]))
dim(na.omit(df.responses[df.responses$items == "NA150",]))
dim(na.omit(df.responses[df.responses$items == "NA110",]))
dim(na.omit(df.responses[df.responses$items == "NA1100",]))
dim(na.omit(df.responses[df.responses$items == "NA1099",]))
dim(na.omit(df.responses[df.responses$items == "NA261",]))
dim(na.omit(df.responses[df.responses$items == "NA260",]))
dim(na.omit(df.responses[df.responses$items == "NA1114",]))
dim(na.omit(df.responses[df.responses$items == "NA289",]))
#Binomial distribution of probabilities if chance-performane is 50%
x <- seq(0,20,by = 1)
y <- dbinom(x,20,0.5)
#plot(x,y,main="Probability distribution assuming per item probability of 50%",
#      xlab="Number of correct answers per items (out of 20 answers)", ylab = "Probability")
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17)])
#first reject items based on accuracy threshold with their paired items
pairs_reject <- df.stim_acc[df.stim_acc$ID %in% items_reject$ID,]
df.responses_clean <- df.responses %>%
filter(!(items %in% pairs_reject$fullID))
#Then check if all verbs still occur twice (also for type 1 items) and reject remaining pair.
pairs_remain <- df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$items,]
pairs_remain <-  unique(pairs_remain[duplicated(pairs_remain$verb_number),"verb_number"])
items_reject2 <- df.stim_acc[!(df.stim_acc$verb_number %in% pairs_remain),]
pairs_reject2 <- df.stim_acc[df.stim_acc$ID %in% items_reject2$ID,]
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% pairs_reject2$fullID))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17)])
df.responses$rating_plausibility
str(df.stim_acc)
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17)])
df.stim_acc
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
df.stim_acc$acc <- round(df.stim_acc$plaus,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17,18)])
#first reject items based on accuracy threshold with their paired items
pairs_reject <- df.stim_acc[df.stim_acc$ID %in% items_reject$ID,]
df.responses_clean <- df.responses %>%
filter(!(items %in% pairs_reject$fullID))
#Then check if all verbs still occur twice (also for type 1 items) and reject remaining pair.
pairs_remain <- df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$items,]
pairs_remain <-  unique(pairs_remain[duplicated(pairs_remain$verb_number),"verb_number"])
items_reject2 <- df.stim_acc[!(df.stim_acc$verb_number %in% pairs_remain),]
pairs_reject2 <- df.stim_acc[df.stim_acc$ID %in% items_reject2$ID,]
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% pairs_reject2$fullID))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17,18)])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==1,])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==2,])
#first reject items based on accuracy threshold with their paired items
pairs_reject <- df.stim_acc[df.stim_acc$ID %in% items_reject$ID,]
df.responses_clean <- df.responses %>%
filter(!(items %in% pairs_reject$fullID))
#Then check if all verbs still occur twice (also for type 1 items) and reject remaining pair.
pairs_remain <- df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$items,]
pairs_remain <-  unique(pairs_remain[duplicated(pairs_remain$verb_number),"verb_number"])
items_reject2 <- df.stim_acc[!(df.stim_acc$verb_number %in% pairs_remain),]
pairs_reject2 <- df.stim_acc[df.stim_acc$ID %in% items_reject2$ID,]
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% pairs_reject2$fullID))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17,18)])
pairs_reject
items_reject
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
df.stim_acc$acc <- round(df.stim_acc$plaus,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17,18)])
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
df.stim_acc$plaus <- round(df.stim_acc$plaus,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17,18)])
#first reject items based on accuracy threshold with their paired items
pairs_reject <- df.stim_acc[df.stim_acc$ID %in% items_reject$ID,]
df.responses_clean <- df.responses %>%
filter(!(items %in% pairs_reject$fullID))
#Then check if all verbs still occur twice (also for type 1 items) and reject remaining pair.
pairs_remain <- df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$items,]
pairs_remain <-  unique(pairs_remain[duplicated(pairs_remain$verb_number),"verb_number"])
items_reject2 <- df.stim_acc[!(df.stim_acc$verb_number %in% pairs_remain),]
pairs_reject2 <- df.stim_acc[df.stim_acc$ID %in% items_reject2$ID,]
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% pairs_reject2$fullID))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17,18)])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==1,])
nrow(stimuli[stimuli$fullID %in% df.responses_clean$items & stimuli$Type==2,])
114/4
items_rejec3 = [VA249,NA249,NA21,VA21,NA243,VA243,NA2104,VA2104,NA247,VA247,NA288,VA288,NA255,VA255,NA237/VA237,NA22,VA22,NA25,VA25,NA24,VA24,NA272,VA272,NA229,VA229,NA286,VA286,NA287,VA287,NA275,VA275,NA278,NA120,VA120,NA133,VA133; NA125,VA125,NA183,VA183; NA188,VA188,NA1101,VA1101;NA147,VA147]
items_rejec3 = c(VA249,NA249,NA21,VA21,NA243,VA243,NA2104,VA2104,NA247,VA247,NA288,VA288,NA255,VA255,NA237/VA237,NA22,VA22,NA25,VA25,NA24,VA24,NA272,VA272,NA229,VA229,NA286,VA286,NA287,VA287,NA275,VA275,NA278,NA120,VA120,NA133,VA133,NA125,VA125,NA183,VA183,NA188,VA188,NA1101,VA1101,NA147,VA147)
items_rejec3 = c(VA249,NA249,NA21,VA21,NA243,VA243,NA2104,VA2104,NA247,VA247,NA288,VA288,NA255,VA255,NA237,VA237,NA22,VA22,NA25,VA25,NA24,VA24,NA272,VA272,NA229,VA229,NA286,VA286,NA287,VA287,NA275,VA275,NA278,NA120,VA120,NA133,VA133,NA125,VA125,NA183,VA183,NA188,VA188,NA1101,VA1101,NA147,VA147)
items_rejec3 = c("VA249","NA249","NA21","VA21","NA243","VA243","NA2104","VA2104","NA247","VA247","NA288","VA288","NA255","VA255","NA237","VA237","NA22","VA22","NA25","VA25","NA24","VA24","NA272","VA272","NA229","VA229","NA286","VA286","NA287","VA287","NA275","VA275","NA278","NA120","VA120","NA133","VA133","NA125","VA125","NA183","VA183","NA188","VA188","NA1101","VA1101","NA147","VA147")
items_reject
#manually reject superfluous items
items_rejec3 = c("VA249","NA249","NA21","VA21","NA243","VA243","NA2104","VA2104","NA247","VA247","NA288","VA288","NA255","VA255","NA237","VA237","NA22","VA22","NA25","VA25","NA24","VA24","NA272","VA272","NA229","VA229","NA286","VA286","NA287","VA287","NA275","VA275","NA278","NA120","VA120","NA133","VA133","NA125","VA125","NA183","VA183","NA188","VA188","NA1101","VA1101","NA147","VA147")
df.responses_final <- df.responses_clean %>%
filter(!(items %in% items_reject3))
#manually reject superfluous items
items_reject3 = c("VA249","NA249","NA21","VA21","NA243","VA243","NA2104","VA2104","NA247","VA247","NA288","VA288","NA255","VA255","NA237","VA237","NA22","VA22","NA25","VA25","NA24","VA24","NA272","VA272","NA229","VA229","NA286","VA286","NA287","VA287","NA275","VA275","NA278","NA120","VA120","NA133","VA133","NA125","VA125","NA183","VA183","NA188","VA188","NA1101","VA1101","NA147","VA147")
df.responses_final <- df.responses_clean %>%
filter(!(items %in% items_reject3))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_final$item,c(1,2,4,6:13,17,18)])
nrow(stimuli[stimuli$fullID %in% df.responses_final$items & stimuli$Type==1,])
nrow(stimuli[stimuli$fullID %in% df.responses_final$items & stimuli$Type==2,])
#manually reject superfluous items
items_reject3 = c("VA249","NA249","NA21","VA21","NA243","VA243","NA2104","VA2104","NA247","VA247","NA288","VA288","NA255","VA255","NA237","VA237","NA22","VA22","NA25","VA25","NA24","VA24","NA272","VA272","NA229","VA229","NA286","VA286","NA287","VA287","NA275","VA275","NA278","VA278","NA120","VA120","NA133","VA133","NA125","VA125","NA183","VA183","NA188","VA188","NA1101","VA1101","NA147","VA147")
df.responses_final <- df.responses_clean %>%
filter(!(items %in% items_reject3))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_final$item,c(1,2,4,6:13,17,18)])
17/20
17/19
#manually reject superfluous items
items_reject3 = c("VA249","NA249","NA21","VA21","NA243","VA243","NA2104","VA2104","NA247","VA247","NA288","VA288","NA255","VA255","NA237","VA237","NA22","VA22","NA25","VA25","NA24","VA24","NA272","VA272","NA229","VA229","NA286","VA286","NA287","VA287","NA275","VA275","NA278","VA278","NA253","VA253","NA120","VA120","NA133","VA133","NA125","VA125","NA183","VA183","NA188","VA188","NA1101","VA1101","NA147","VA147")
df.responses_clean <- df.responses_clean %>%
filter(!(items %in% items_reject3))
datatable(df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,c(1,2,4,6:13,17,18)])
getwd()
final_stim = df.stim_acc[df.stim_acc$fullID %in% df.responses_clean$item,]
final_stim
dim(final_stim)
write.csv(final_stim,'stimuluslist_final.csv')
datatable(items_reject[c(66,67),])
items_reject
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
df.stim_acc$plaus <- round(df.stim_acc$plaus,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17,18)])
datatable(items_reject[c(66,67),])
dim(items_reject)
items_reject[c(66,67),]
setwd("/Users/sophiearana/Documents/prepositionalphrase/preps/Limesurvey/results/")
library(plotly)
library(ggplot2)
library(reshape)
library(RColorBrewer)
library(data.table)
library(plyr)
library(dplyr)
library(MASS)
select <- dplyr::select
library(kableExtra)
library(knitr)
library(shiny)
library(DT)
options(knitr.table.format="html")
#Create color scheme
pastel_colors = brewer.pal(8, "Pastel1")
set_colors = brewer.pal(8, "Set1")
stimuli         <- read.csv(file="allstimuli_new.csv",head=TRUE,sep=";",na.strings = c("","NAN"), stringsAsFactors = FALSE,encoding="UTF-8")
stimuli$fullID  <- as.character(interaction(stimuli[,c(13,3)],sep = ""))
stimuli$Condition <- as.factor(stimuli$Condition)
colnames(stimuli) <- c("Type","Pair","ID","Det.","N0","Verb","Det.2","N1","Prep.","Det.3","Adj.","N2","Attachment","Unambiguous","verb_number","fullID")
#load response file
file_names = list.files(pattern="^results",path = "allresponses",full.names = TRUE)
temp <- lapply(file_names,read.csv,sep=",",na.strings = c("","NAN"), stringsAsFactors = TRUE)
df.responses <- Reduce(function(x,y) merge(x,y,all=TRUE,sort=TRUE),temp)
#transpose and fix column names and classes
df.responses                <- setDT(df.responses,keep.rownames = TRUE)
colnames(df.responses)[1]   <- "subjects"
df.responses                <- Filter(function(x) !(all(x=="")), df.responses) #delete blank columns
#Split all item specific data from subject specific data
ind_items   <- grep("[VN]A[0-9]",colnames(df.responses),value = TRUE)
df.subjectinfo <- df.responses
df.subjectinfo[,ind_items] <- NULL
df.responses  <- df.responses[,c("subjects",ind_items),with=FALSE]
#reshape items so that each row contains info for items per subject (items repeat over rows)
ind             <- grep("^[VN]A[0-9]*$",colnames(df.responses),value = TRUE)
df.respAttach   <- df.responses[,c("subjects",ind),with=FALSE]
df.respAttach   <- melt(df.respAttach,id="subjects",value.name="response_attachment",variable.name='items')
ind             <- grep("^[VN]A[0-9]*Time$",colnames(df.responses),value = TRUE)
df.respTime     <- df.responses[,c("subjects",ind),with=FALSE]
df.respTime     <- melt(df.respTime,id="subjects",value.name="rt_attachment",variable.name='items')
ind             <- grep("\\.$",colnames(df.responses),value = TRUE)
df.respPAttach  <- df.responses[,c("subjects",ind),with=FALSE]
df.respPAttach  <- melt(df.respPAttach,id="subjects",value.name="rating_plausibility",variable.name='items')
ind             <- grep("P[VN]A[0-9]*Time$",colnames(df.responses),value = TRUE)
df.respPTime    <- df.responses[,c("subjects",ind),with=FALSE]
df.respPTime    <- melt(df.respPTime,id="subjects",value.name="rt_plausibility",variable.name='items')
df.responses    <- cbind(df.respAttach,df.respTime[,3],df.respPAttach[,3],df.respPTime[,3])
df.responses$hits <- as.numeric((grepl("N",df.responses$items) & df.responses$response_attachment == "Nomen") |
(grepl("V",df.responses$items) & df.responses$response_attachment == "Verb"))
df.responses    <- df.responses %>%
mutate(attachment = ifelse(grepl("N",items),"Noun","Verb"))
least_correct = 3
threshhold_acc = 0.60
avg_rts <- df.responses %>%
group_by(subjects) %>%
summarise(mean_rt = mean(rt_attachment,na.rm=TRUE))
outlier <- boxplot.stats(avg_rts$mean_rt)$out
p <- ggplot(avg_rts, aes(x=factor(0),y=mean_rt,subject=subjects)) +
geom_boxplot() +
geom_jitter(size = 2) +
ggtitle("Average reaction times per subject across all items")
p <- ggplotly(p,tooltip ='subjects')
p
test_correct   <- df.subjectinfo %>%
select(subjects,starts_with("correct")) %>%
mutate(number_correct = rowSums(!is.na(.[,2:ncol(.)]))) %>%
select(subjects,number_correct)
avg_unambiguous <-df.responses %>%
filter(items %in% subset_unambiguous) %>%
group_by(subjects) %>%
summarise(acc_unambiguous = mean(hits,na.rm=TRUE))
summ <- join_all(list(avg_rts,test_correct,avg_unambiguous),by='subjects')
DT::datatable(summ) %>% formatRound(columns=colnames(summ),digits=2)
outlier_indx <- avg_rts$subjects[which(round(avg_rts$mean_rt,digits=2) %in% round(outlier,digits=2))]
outlier_indx <- c(outlier_indx,summ$subjects[which(summ$number_correct < least_correct | summ$acc_unambiguous < threshhold_acc)])
outlier_indx <- unique(outlier_indx)
#Remove Outlier
df.responses <- df.responses %>%
filter(!(subjects %in% outlier_indx))
threshold = 0.72
acc_per_item <- df.responses %>%
group_by(items) %>%
summarise(acc = mean(hits,na.rm = TRUE), plaus = mean(rating_plausibility,na.rm = TRUE))
mean_accuracy <- acc_per_item %>%
summarise(mean_correct = mean(acc,na.rm = TRUE))
df.stim_acc <- merge(stimuli,acc_per_item,by.x="fullID",by.y="items")
df.stim_acc$acc <- round(df.stim_acc$acc,digits=2)
df.stim_acc$plaus <- round(df.stim_acc$plaus,digits=2)
items_reject <- df.stim_acc %>% arrange(Verb) %>% filter(acc < threshold)
#datatable(items_reject[,c(1,2,4,6:13,17)],
#          filter = 'top',
#          options = list("pageLength" = 10))
datatable(items_reject[,c(1,2,4,6:13,17,18)])
df.stim_acc[df.stim_acc$fullID=="VA116",]
df.stim_acc[df.stim_acc$fullID=="NA116",]
df.stim_acc[df.stim_acc$verb_number=="113",]
df.stim_acc[df.stim_acc$verb_number=="92",]
df.stim_acc[df.stim_acc$fullID=="NA120",]
df.stim_acc[df.stim_acc$verb_number=="91",]
df.stim_acc[df.stim_acc$fullID=="VA147",]
df.stim_acc[df.stim_acc$verb_number=="172",]
df.stim_acc[df.stim_acc$fullID=="NA147",]
df.stim_acc[df.stim_acc$fullID=="NA1101",]
df.stim_acc[df.stim_acc$verb_number=="61",]
df.stim_acc[df.stim_acc$fullID=="VA1101",]
df.stim_acc[df.stim_acc$verb_number=="23",]
df.stim_acc[df.stim_acc$fullID=="VA188",]
df.stim_acc[df.stim_acc$fullID=="VA183",]
df.stim_acc[df.stim_acc$fullID=="NA183",]
df.stim_acc[df.stim_acc$verb_number=="33",]
df.stim_acc[df.stim_acc$verb_number=="84",]
df.stim_acc[df.stim_acc$fullID=="NA133",]
